{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Natural Language and Distibuted Representations\n",
    "\n",
    "## 2.1. Natural Language Processing\n",
    "\n",
    "## 2.2 Thesaurus\n",
    "\n",
    "Thesaurus is a list of words and their synonyms.\n",
    "It has been created by the [wordnet](https://wordnet.princeton.edu/) project.\n",
    "But there are problems in using thesaurus for natural language processing because it need a lot of work to keep updating according to word meaning change and new word is added.\n",
    "\n",
    "## 2.3 Count base method\n",
    "\n",
    "Text data acuired for the purpose of understanding natural language is called 'corpus'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use corpus\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "text = text.lower()\n",
    "text = text.replace('.', ' .')\n",
    "\n",
    "words = text.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ')\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id)\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word\n",
    "    \n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)\n",
    "print(word_to_id)\n",
    "print(id_to_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Distributed Representations\n",
    "\n",
    "Vector expression of words to cacth the \"meaning of word\" is called 'distributed representations'.\n",
    "\n",
    "### 2.3.3 Ditsributional hypothesis\n",
    "\n",
    "The ida of distributional hypothesis is that the meaning of a word is formed by the words that surround it.\n",
    "\n",
    "### 2.3.4 Co-occurence matrix\n",
    "\n",
    "Focus on a particular word, count the words that appear aroiund it, and tally them up.\n",
    "\n",
    "For text `'you say goodbye and i say hello.'`, only 'say' appears around 'I', but if focus on 'say', the 'goodbye' and 'hello' are counted.\n",
    "This can be shown in following table.\n",
    "\n",
    "| | you | say | goodbye | and | i | hello | . |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| you | 0 | 1 | 0 | 0 | 0 | 0 | 0 |\n",
    "| say | 1 | 0 | 1 | 0 | 1 | 1 | 0 |\n",
    "| goodbye | 0 | 1 | 0 | 1 | 0 | 0 | 0 |\n",
    "| and | 0 | 0 | 1 | 0 | 1 | 0 | 0 |\n",
    "| i | 0 | 1 | 0 | 1 | 0 | 0 | 0 |\n",
    "| hello | 0 | 1 | 0 | 0 | 0 | 0 | 1 |\n",
    "| . | 0 | 0 | 0 | 0 | 0 | 1 | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0]\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append(\"../.org/deep-learning-from-scratch-2/\")\n",
    "import numpy as np\n",
    "\n",
    "C = np.array([\n",
    "    [0, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0],\n",
    "], dtype=np.int32)\n",
    "\n",
    "print(C[word_to_id['goodbye']])\n",
    "\n",
    "\n",
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32)\n",
    "\n",
    "    for idx, word_id in enumerate(corpus):\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0xffff6467a070>\n"
     ]
    }
   ],
   "source": [
    "test = enumerate(corpus)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Similarity of word vectors\n",
    "\n",
    "$$\n",
    "    similarity(x,y) = \\frac{x\\cdot y}{\\|x\\|\\|y\\|} =\\frac{x_1 y_1 + \\cdots + x_n y_n}{\\sqrt{x_1^2 + \\cdots + x_n^2} \\sqrt{y_1^2 + \\cdots + y_n^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y**2)) + eps)\n",
    "    return np.dot(nx, ny)\n",
    "\n",
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "\n",
    "    if query not in word_to_id:\n",
    "        print('%s is not found' % query)\n",
    "        return\n",
    "    \n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "\n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067691154799"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../.org/deep-learning-from-scratch-2/\")\n",
    "import numpy as np\n",
    "# from common.util import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "cos_similarity(c0, c1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] goodbye\n",
      " i: 0.9999999858578643\n",
      " you: 0.7071067691154799\n",
      " hello: 0.49999999292893216\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../.org/deep-learning-from-scratch-2/\")\n",
    "import numpy as np\n",
    "#from common.util import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "most_similar('goodbye', word_to_id, id_to_word, C, top=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Improwing count based method\n",
    "\n",
    "Count base method tend to show high similarity for the word which appear more frequently.\n",
    "To solving this, there is a method to use Pointwise Mutual Information(PMI) which is used to calculate the similarity of two words and appearance ratio.\n",
    "\n",
    "PMI is calculated as follows.\n",
    "\n",
    "$$\n",
    "    PMI(x,y) = \\log _2\\frac{p(x,y)}{p(x)p(y)}\n",
    "$$\n",
    "\n",
    "When both value x and y are zero, PMI is set as -infinity.\n",
    "PPMI is used to reduce the effect of zero values(minus value is translated to zero).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100) == 0:\n",
    "                    print('%.1f%% done' % (100*cnt/total))\n",
    "\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-occurence matrix\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n",
      "(7, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "print('Co-occurence matrix')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Dimensionality reduction\n",
    "\n",
    "Problem of PPMI is that it is a sparse matrix.\n",
    "To solve this problem, Dimentionality reduction like Singluar Value Decomposition(SVD) is used.\n",
    "\n",
    "$$\n",
    "    X = U S V^T\n",
    "$$\n",
    "\n",
    "### 2.4.3 Dimensionality reduction by SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n",
      "[[-3.409e-01 -1.110e-16 -4.441e-16  1.205e-01  9.323e-01  0.000e+00\n",
      "   3.207e-16]\n",
      " [ 0.000e+00 -5.976e-01  1.802e-01  0.000e+00  0.000e+00 -7.812e-01\n",
      "   0.000e+00]\n",
      " [-4.363e-01 -5.551e-17 -2.220e-16  5.088e-01 -2.253e-01 -1.388e-17\n",
      "  -7.071e-01]\n",
      " [-3.579e-16 -4.978e-01  6.804e-01  1.240e-16  8.184e-17  5.378e-01\n",
      "  -8.846e-17]\n",
      " [-4.363e-01 -4.329e-17 -2.217e-16  5.088e-01 -2.253e-01 -1.804e-17\n",
      "   7.071e-01]\n",
      " [-7.092e-01 -4.329e-17 -2.217e-16 -6.839e-01 -1.710e-01 -1.804e-17\n",
      "  -1.048e-16]\n",
      " [ 4.899e-16 -6.285e-01 -7.103e-01 -1.706e-16 -2.240e-16  3.169e-01\n",
      "   1.139e-16]]\n",
      "[3.168e+00 3.168e+00 2.703e+00 2.703e+00 1.514e+00 1.514e+00 1.608e-16]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(W)\n",
    "\n",
    "print(C)\n",
    "print(W)\n",
    "print(U)\n",
    "print(S)\n",
    "#print(V)\n",
    "\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "\n",
    "plt.scatter(U[:,0], U[:,1], alpha=0.5)\n",
    "plt.xlim(-0.75, 0.75)\n",
    "plt.ylim(-0.75, 0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 PTB Data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "corpus size: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id[\"car\"]: 3856\n",
      "word_to_id[\"happy\"]: 4428\n",
      "word_to_id[\"lexus\"]: 7426\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../.org/deep-learning-from-scratch-2/\")\n",
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print('corpus size:', len(corpus))\n",
    "print('corpus[:30]:', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print('word_to_id[\"car\"]:', word_to_id['car'])\n",
    "print('word_to_id[\"happy\"]:', word_to_id['happy'])\n",
    "print('word_to_id[\"lexus\"]:', word_to_id['lexus'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5 Evaluation of PTB Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting co-occurences ...\n",
      "calculating PPMI ...\n",
      "1.0% done\n",
      "2.0% done\n",
      "3.0% done\n",
      "4.0% done\n",
      "5.0% done\n",
      "6.0% done\n",
      "7.0% done\n",
      "8.0% done\n",
      "9.0% done\n",
      "10.0% done\n",
      "11.0% done\n",
      "12.0% done\n",
      "13.0% done\n",
      "14.0% done\n",
      "15.0% done\n",
      "16.0% done\n",
      "17.0% done\n",
      "18.0% done\n",
      "19.0% done\n",
      "20.0% done\n",
      "21.0% done\n",
      "22.0% done\n",
      "23.0% done\n",
      "24.0% done\n",
      "25.0% done\n",
      "26.0% done\n",
      "27.0% done\n",
      "28.0% done\n",
      "29.0% done\n",
      "30.0% done\n",
      "31.0% done\n",
      "32.0% done\n",
      "33.0% done\n",
      "34.0% done\n",
      "35.0% done\n",
      "36.0% done\n",
      "37.0% done\n",
      "38.0% done\n",
      "39.0% done\n",
      "40.0% done\n",
      "41.0% done\n",
      "42.0% done\n",
      "43.0% done\n",
      "44.0% done\n",
      "45.0% done\n",
      "46.0% done\n",
      "47.0% done\n",
      "48.0% done\n",
      "49.0% done\n",
      "50.0% done\n",
      "51.0% done\n",
      "52.0% done\n",
      "53.0% done\n",
      "54.0% done\n",
      "55.0% done\n",
      "56.0% done\n",
      "57.0% done\n",
      "58.0% done\n",
      "59.0% done\n",
      "60.0% done\n",
      "61.0% done\n",
      "62.0% done\n",
      "63.0% done\n",
      "64.0% done\n",
      "65.0% done\n",
      "66.0% done\n",
      "67.0% done\n",
      "68.0% done\n",
      "69.0% done\n",
      "70.0% done\n",
      "71.0% done\n",
      "72.0% done\n",
      "73.0% done\n",
      "74.0% done\n",
      "75.0% done\n",
      "76.0% done\n",
      "77.0% done\n",
      "78.0% done\n",
      "79.0% done\n",
      "80.0% done\n",
      "81.0% done\n",
      "82.0% done\n",
      "83.0% done\n",
      "84.0% done\n",
      "85.0% done\n",
      "86.0% done\n",
      "87.0% done\n",
      "88.0% done\n",
      "89.0% done\n",
      "90.0% done\n",
      "91.0% done\n",
      "92.0% done\n",
      "93.0% done\n",
      "94.0% done\n",
      "95.0% done\n",
      "96.0% done\n",
      "97.0% done\n",
      "98.0% done\n",
      "99.0% done\n",
      "100.0% done\n",
      "calculating SVD ...\n",
      "\n",
      "[query] you\n",
      " i: 0.7095709443092346\n",
      " we: 0.635583758354187\n",
      " 'll: 0.5492595434188843\n",
      " anybody: 0.5316736698150635\n",
      " do: 0.5247924327850342\n",
      "\n",
      "[query] year\n",
      " quarter: 0.6982716917991638\n",
      " month: 0.6671340465545654\n",
      " third: 0.6542332172393799\n",
      " last: 0.6181087493896484\n",
      " february: 0.6016016602516174\n",
      "\n",
      "[query] car\n",
      " auto: 0.6762186288833618\n",
      " luxury: 0.5659862756729126\n",
      " vehicle: 0.5530803203582764\n",
      " domestic: 0.5299400687217712\n",
      " cars: 0.5074983835220337\n",
      "\n",
      "[query] toyota\n",
      " motor: 0.7527785301208496\n",
      " nissan: 0.6702644228935242\n",
      " lexus: 0.6532653570175171\n",
      " motors: 0.6245168447494507\n",
      " honda: 0.5835803151130676\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../.org/deep-learning-from-scratch-2/\")\n",
    "import numpy as np\n",
    "# from common.util import most_similar, create_co_matrix, ppmi\n",
    "from dataset import ptb\n",
    "\n",
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('counting co-occurences ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('calculating PPMI ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "try:\n",
    "    # truncated SVD\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)\n",
    "\n",
    "except ImportError:\n",
    "    # SVD\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "U"
    ]
   },
   "source": [
    "# Appendix B: WordNet\n",
    "\n",
    "## B.1 Install NLTK\n",
    "\n",
    "`pip install nltk`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2 Get synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "wordnet.synsets('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a motor vehicle with four wheels; usually propelled by an internal combustion engine\n",
      "['car', 'auto', 'automobile', 'machine', 'motorcar']\n"
     ]
    }
   ],
   "source": [
    "car = wordnet.synset('car.n.01')\n",
    "print(car.definition())\n",
    "print(car.lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.3 WordNet and terms network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('entity.n.01'),\n",
       " Synset('physical_entity.n.01'),\n",
       " Synset('object.n.01'),\n",
       " Synset('whole.n.02'),\n",
       " Synset('artifact.n.01'),\n",
       " Synset('instrumentality.n.03'),\n",
       " Synset('container.n.01'),\n",
       " Synset('wheeled_vehicle.n.01'),\n",
       " Synset('self-propelled_vehicle.n.01'),\n",
       " Synset('motor_vehicle.n.01'),\n",
       " Synset('car.n.01')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.hypernym_paths()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.4 Semantic similarity according to WordNet\n",
    "\n",
    "Similarity can be measured by using `path_similarity` or `wup_similarity`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05555555555555555\n",
      "0.07692307692307693\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "car = wordnet.synset('car.n.01')\n",
    "novel = wordnet.synset('novel.n.01')\n",
    "dog = wordnet.synset('dog.n.01')\n",
    "motorcycle = wordnet.synset('motorcycle.n.01')\n",
    "\n",
    "print(car.path_similarity(novel))\n",
    "print(car.path_similarity(dog))\n",
    "print(car.path_similarity(motorcycle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
